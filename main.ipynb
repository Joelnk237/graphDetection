{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52719697-b4a8-4fbd-ac5e-62e98523ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "##DEFINITION DER DATENSTRUKTUR\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}  # {node_id: (x, y)}\n",
    "        self.edges = []  # [(node_id1, node_id2)]\n",
    "\n",
    "    def add_node(self, node_id, x, y):\n",
    "        self.nodes[node_id] = (x, y)\n",
    "\n",
    "    def add_edge(self, node1, node2):\n",
    "        self.edges.append((node1, node2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8462b9a4-8fa2-427e-9219-f6c1eb160304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNKTION ZUM PLOTTEN DER GRAPHEN\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_graph(graph):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    node_radius = 10\n",
    "\n",
    "    # Zeichnen der Kanten\n",
    "    for node1, node2 in graph.edges:\n",
    "        x1, y1 = graph.nodes[node1]\n",
    "        x2, y2 = graph.nodes[node2]\n",
    "        ax.plot([x1, x2], [y1, y2], 'k-', zorder=1)  # Schwarze Linie für Kanten\n",
    "\n",
    "    # Zeichnen der Knoten\n",
    "    for node_id, (x, y) in graph.nodes.items():\n",
    "        # Zeichnen Sie für jeden Knoten einen schwarzen Kreis\n",
    "        circle = plt.Circle((x, y), node_radius, color='black', zorder=2)\n",
    "        ax.add_artist(circle)\n",
    "        # die ID innerhalb des Kreises hinzufügen\n",
    "        ax.text(x, y, str(node_id), color='white', fontsize=10, ha='center', va='center', zorder=3)\n",
    "    # Konfigurieren der Achsen\n",
    "    ax.set_aspect('equal')\n",
    "    # Passen Sie die Achsengrenzen an, um sicherzustellen, dass das Diagramm deutlich sichtbar ist\n",
    "    x_values, y_values = zip(*graph.nodes.values())\n",
    "    ax.set_xlim(min(x_values) - node_radius, max(x_values) + node_radius)\n",
    "    ax.set_ylim(min(y_values) - node_radius, max(y_values) + node_radius)\n",
    "    #plt.xlabel(\"X\")\n",
    "    #plt.ylabel(\"Y\")\n",
    "\n",
    "    # Entfernen der Achsennummerierung\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.axis('off')  # Optionnel pour enlever aussi les bordures de l'axe\n",
    "    plt.title(\"Graph Visualization\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05b1ca6-d6d7-4cf3-9c6b-849af4e96106",
   "metadata": {},
   "outputs": [],
   "source": [
    "##HOUGH-LINE-DETECTION ALGORITHMUS\n",
    "\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import math\n",
    "def find_hough_lines(image, edge_image, num_rhos, num_thetas, bin_threshold):\n",
    "  #image size\n",
    "  img_height, img_width = edge_image.shape[:2]\n",
    "  img_height_half = img_height / 2\n",
    "  img_width_half = img_width / 2\n",
    "  \n",
    "  # Rho and Theta ranges\n",
    "  diag_len = np.sqrt(np.square(img_height) + np.square(img_width))\n",
    "  dtheta = 180 / num_thetas\n",
    "  drho = (2 * diag_len) / num_rhos\n",
    "  \n",
    "  ## Thetas is bins created from 0 to 180 degree with increment of the provided dtheta\n",
    "  thetas = np.arange(0, 180, step=dtheta)\n",
    "  \n",
    "  ## Rho ranges from -diag_len to diag_len where diag_len is the diagonal length of the input image\n",
    "  rhos = np.arange(-diag_len, diag_len, step=drho)\n",
    "  \n",
    "  # Calculate Cos(theta) and Sin(theta) it will be required later on while calculating rho\n",
    "  cos_thetas = np.cos(np.deg2rad(thetas))\n",
    "  sin_thetas = np.sin(np.deg2rad(thetas))\n",
    "  \n",
    "  # Hough accumulator array of theta vs rho, (rho,theta)\n",
    "  accumulator = np.zeros((len(rhos), len(thetas)))\n",
    "  \n",
    "  # Hough Space plot for the image.\n",
    "  #figure = plt.figure()\n",
    "  #hough_plot = figure.add_subplot()\n",
    "  #hough_plot.set_facecolor((0, 0, 0))\n",
    "  #hough_plot.title.set_text(\"Hough Space\")\n",
    "  \n",
    "  # Iterate through pixels and if non-zero pixel process it for hough space\n",
    "  for y in range(img_height):\n",
    "    for x in range(img_width):\n",
    "      if edge_image[y][x] != 0: #white pixel\n",
    "        edge_pt = [y - img_height_half, x - img_width_half]\n",
    "        hough_rhos, hough_thetas = [], [] \n",
    "        \n",
    "        # Iterate through theta ranges to calculate the rho values\n",
    "        for theta_idx in range(len(thetas)):\n",
    "          # Calculate rho value\n",
    "          rho = (edge_pt[1] * cos_thetas[theta_idx]) + (edge_pt[0] * sin_thetas[theta_idx])\n",
    "          theta = thetas[theta_idx]\n",
    "          \n",
    "          # Get index of nearest rho value\n",
    "          rho_idx = np.argmin(np.abs(rhos - rho))\n",
    "          \n",
    "          #increment the vote for (rho_idx,theta_idx) pair\n",
    "          accumulator[rho_idx][theta_idx] += 1\n",
    "          \n",
    "          # Append values of rho and theta in hough_rhos and hough_thetas respectively for Hough Space plotting.\n",
    "          hough_rhos.append(rho)\n",
    "          hough_thetas.append(theta)\n",
    "        \n",
    "        # Plot Hough Space from the values\n",
    "        #hough_plot.plot(hough_thetas, hough_rhos, color=\"white\", alpha=0.05)\n",
    "\n",
    "  # accumulator, thetas, rhos are calculated for entire image, Now return only the ones which have higher votes. \n",
    "  # if required all can be returned here, the below code could be post processing done by the user.\n",
    "  \n",
    "  # Output image with detected lines drawn\n",
    "  output_img = image.copy()\n",
    "  # Output list of detected lines. A single line would be a tuple of (rho,theta,x1,y1,x2,y2) \n",
    "  out_lines = []\n",
    "  \n",
    "  for y in range(accumulator.shape[0]):\n",
    "    for x in range(accumulator.shape[1]):\n",
    "      #print(f\"nombre de votes:( {accumulator[y][x]} ) \") # If number of votes is greater than bin_threshold provided shortlist it as a candidate line\n",
    "      if accumulator[y][x] > bin_threshold:\n",
    "        rho = rhos[y]\n",
    "        theta = thetas[x]\n",
    "        \n",
    "        # a and b are intercepts in x and y direction\n",
    "        a = np.cos(np.deg2rad(theta))\n",
    "        b = np.sin(np.deg2rad(theta))\n",
    "        \n",
    "        x0 = (a * rho) + img_width_half\n",
    "        y0 = (b * rho) + img_height_half\n",
    "        \n",
    "        # Get the extreme points to draw the line\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Draw line on the output image\n",
    "        output_img = cv2.line(output_img, (x1,y1), (x2,y2), (0,255,0), 1)\n",
    "        \n",
    "        # Add the data for the line to output list\n",
    "        out_lines.append((rho,theta,x1,y1,x2,y2))\n",
    "\n",
    " \n",
    "  \n",
    "  return output_img, out_lines\n",
    "\n",
    "\n",
    "def proceed(img , box):\n",
    "    num_rho = 180\n",
    "    num_theta = 180\n",
    "    bin_threshold = 20\n",
    "    lines_are_white = True\n",
    "    input_img = img\n",
    "    #input_img = cv2.imread('./TestRoi.jpg')\n",
    "    #Edge detection on the input image\n",
    "    edge_image = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, edge_image = cv2.threshold(edge_image, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "    #edge_image = cv2.Canny(edge_image, 100, 200)\n",
    "    \n",
    "    if edge_image is not None:\n",
    "            \n",
    "        #print (\"Detecting Hough Lines Started!\")\n",
    "        line_img, lines = find_hough_lines(input_img, edge_image, num_rho, num_theta, bin_threshold)\n",
    "        \n",
    "        #cv2.imshow('Detected Lines', line_img)\n",
    "        #print(f\"nombre de lignes detectes:( {len(lines)} ) \")\n",
    "        if (len(lines) == 0):\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            return (xmin,ymin),(xmax, ymax)\n",
    "        first_line = lines[(int)(len(lines) / 2)]\n",
    "        rho, theta, x1, y1, x2, y2 = first_line\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        first_line_img = input_img.copy()\n",
    "\n",
    "        if(((y2-y1)/(x2-x1)) > 0):\n",
    "            #print(\"pente vers la gauche\")\n",
    "            return (xmin,ymin),(xmax, ymax)\n",
    "        else:\n",
    "            #print(\"pente vers la droite\")\n",
    "            return (xmax,ymin),(xmin, ymax)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print (\"Error in input image!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae185988-f228-49d2-8092-b34750caa0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "d2l 1.0.3 requires numpy==1.23.5, but you have numpy 1.26.4 which is incompatible.\n",
      "optimum 1.20.0 requires transformers[sentencepiece]<4.42.0,>=4.26.0, but you have transformers 4.46.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2\" --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24e15c4-fbfc-4d39-9a23-e4089c2ca1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.70-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (3.7.2)\n",
      "Collecting opencv-python>=4.6.0 (from ultralytics)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (1.10.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (4.66.6)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ultralytics) (6.1.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.11/site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Collecting sympy==1.13.1 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.70-py3-none-any.whl (914 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m914.9/914.9 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, sympy, opencv-python, ultralytics-thop, ultralytics\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "optimum 1.20.0 requires transformers[sentencepiece]<4.42.0,>=4.26.0, but you have transformers 4.46.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed opencv-python-4.11.0.86 py-cpuinfo-9.0.0 sympy-1.13.1 ultralytics-8.3.70 ultralytics-thop-2.0.14\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/home/mambauser/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "from ultralytics import YOLO    #ultralytics importierem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e349524b-6c91-47a9-88e0-601c5408f8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.11/site-packages (2.15.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.54.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (2.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from tensorboard) (4.21.12)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (75.3.0)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard) (3.1.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
      "Ultralytics 8.3.69 🚀 Python-3.11.10 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4090, 24195MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=./data.yaml, epochs=25, time=None, patience=5, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=0, project=./runs/tensorboard, name=graph_detection18, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/tensorboard/graph_detection18\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/tensorboard/graph_detection18', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/Projekt/test/train/labels... 86 images, 0 backgrounds, 0 corrupt: 100%|██████████| 86/86 [00:00<00:00, 1740.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /workspace/Projekt/test/train/images/3cb888d7-graph7.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /workspace/Projekt/test/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/Projekt/test/val/labels... 20 images, 0 backgrounds, 0 corrupt: 100%|██████████| 20/20 [00:00<00:00, 1854.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /workspace/Projekt/test/val/labels.cache\n",
      "Plotting labels to runs/tensorboard/graph_detection18/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/tensorboard/graph_detection18\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/25      1.35G       1.55      3.877      1.311        285        416: 100%|██████████| 6/6 [00:01<00:00,  3.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615     0.0145      0.147    0.00867    0.00482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/25       1.2G       1.41       3.54      1.206        218        416: 100%|██████████| 6/6 [00:01<00:00,  4.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615     0.0658      0.658     0.0871     0.0587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/25      1.31G      1.128      2.689     0.9939        284        416: 100%|██████████| 6/6 [00:01<00:00,  4.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615     0.0862      0.848      0.182      0.128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/25      1.19G      1.131      1.935     0.9717        164        416: 100%|██████████| 6/6 [00:01<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615     0.0929      0.909      0.523      0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/25       1.3G      1.067      1.558     0.9307        301        416: 100%|██████████| 6/6 [00:01<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.905      0.143      0.725      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/25      1.19G       1.06      1.233     0.9294        244        416: 100%|██████████| 6/6 [00:01<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.908      0.465      0.837      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/25      1.34G      1.052      1.076     0.9171        195        416: 100%|██████████| 6/6 [00:01<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.874      0.694      0.852      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/25      1.21G      1.016     0.8735     0.9236        210        416: 100%|██████████| 6/6 [00:01<00:00,  4.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.835      0.755      0.841      0.624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/25      1.36G      1.013     0.8254     0.9276        216        416: 100%|██████████| 6/6 [00:01<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.831      0.834      0.859      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/25      1.22G     0.9844     0.7922     0.9142        240        416: 100%|██████████| 6/6 [00:01<00:00,  4.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.899      0.913      0.908      0.673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/25      1.29G     0.9627     0.7616     0.9082        304        416: 100%|██████████| 6/6 [00:01<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615       0.93      0.939      0.947       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/25      1.28G     0.9458     0.7128     0.9112        199        416: 100%|██████████| 6/6 [00:01<00:00,  4.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.951      0.946      0.976      0.741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/25      1.32G     0.9173     0.7009     0.9063        284        416: 100%|██████████| 6/6 [00:01<00:00,  4.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.982      0.937      0.983      0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/25      1.28G     0.9249     0.6773     0.9127        174        416: 100%|██████████| 6/6 [00:01<00:00,  4.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.968      0.949      0.979      0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/25      1.29G     0.9066      0.664     0.9098        236        416: 100%|██████████| 6/6 [00:01<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.975      0.958       0.98      0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/25       1.1G     0.8166     0.6484     0.8811        166        416: 100%|██████████| 6/6 [00:00<00:00,  7.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.958      0.978      0.981      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/25      1.05G     0.8349     0.6764     0.8947        176        416: 100%|██████████| 6/6 [00:00<00:00,  8.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.972      0.977      0.987      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/25      1.05G     0.8183     0.6423     0.8997        150        416: 100%|██████████| 6/6 [00:00<00:00,  8.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.981      0.972      0.989      0.771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/25      1.07G     0.8262     0.6236     0.8851        179        416: 100%|██████████| 6/6 [00:00<00:00,  8.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.973      0.966      0.986      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/25      1.04G     0.7789     0.6007     0.8867        167        416: 100%|██████████| 6/6 [00:00<00:00,  8.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.963      0.971      0.986      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/25      1.05G     0.7598     0.5812     0.8774        179        416: 100%|██████████| 6/6 [00:00<00:00,  8.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.953      0.968      0.986      0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/25      1.07G     0.7772     0.5787     0.8837        155        416: 100%|██████████| 6/6 [00:00<00:00,  8.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.945      0.973      0.988      0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/25      1.04G     0.7714      0.573     0.8747        172        416: 100%|██████████| 6/6 [00:00<00:00,  8.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.946      0.973      0.989      0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/25      1.07G     0.7752     0.5866     0.8782        154        416: 100%|██████████| 6/6 [00:00<00:00,  8.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.964      0.975       0.99      0.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/25      1.04G     0.7609     0.5709     0.8743        158        416: 100%|██████████| 6/6 [00:00<00:00,  8.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 11.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.975      0.975       0.99      0.801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25 epochs completed in 0.013 hours.\n",
      "Optimizer stripped from runs/tensorboard/graph_detection18/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/tensorboard/graph_detection18/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/tensorboard/graph_detection18/weights/best.pt...\n",
      "Ultralytics 8.3.69 🚀 Python-3.11.10 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4090, 24195MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.975      0.975       0.99      0.801\n",
      "                  edge         20        323       0.95       0.96      0.986       0.76\n",
      "                  node         20        292          1       0.99      0.995      0.841\n",
      "Speed: 0.0ms preprocess, 0.2ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/tensorboard/graph_detection18\u001b[0m\n",
      "Ultralytics 8.3.69 🚀 Python-3.11.10 torch-2.5.1 CUDA:0 (NVIDIA GeForce RTX 4090, 24195MiB)\n",
      "Model summary (fused): 168 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/Projekt/test/val/labels.cache... 20 images, 0 backgrounds, 0 corrupt: 100%|██████████| 20/20 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         20        615      0.977      0.975       0.99      0.801\n",
      "                  edge         20        323      0.953       0.96      0.986      0.761\n",
      "                  node         20        292          1       0.99      0.995      0.841\n",
      "Speed: 0.3ms preprocess, 0.5ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/tensorboard/graph_detection182\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f2e015e0190>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.065643,    0.032822,           0],\n",
       "       [          1,           1,           1, ...,           1,           1,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.18426,     0.18426,     0.18426, ...,           0,           0,           0],\n",
       "       [    0.18718,     0.18718,     0.18718, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.10151,     0.10151,     0.10151, ...,           1,           1,           1],\n",
       "       [    0.10325,     0.10325,     0.10325, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.9969,      0.9969,      0.9969, ...,           0,           0,           0],\n",
       "       [          1,           1,           1, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.820047050711392\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.76131,     0.84091])\n",
       "names: {0: 'edge', 1: 'node'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9767182485429469, 'metrics/recall(B)': 0.9750836545127834, 'metrics/mAP50(B)': 0.9904912733633846, 'metrics/mAP50-95(B)': 0.8011088037500593, 'fitness': 0.820047050711392}\n",
       "save_dir: PosixPath('runs/tensorboard/graph_detection182')\n",
       "speed: {'preprocess': 0.3032684326171875, 'inference': 0.4857182502746582, 'loss': 0.00040531158447265625, 'postprocess': 0.5555868148803711}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DAS MODELL TRAINIEREN\n",
    "\n",
    "!pip install tensorboard\n",
    "# Modell laden\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Das Modell trainiern\n",
    "model.train(\n",
    "    data='./data.yaml',\n",
    "    epochs=25,\n",
    "    imgsz=416,\n",
    "    batch=16,                 # Batch-größe\n",
    "    workers=0,\n",
    "    name='graph_detection',\n",
    "    patience=5,               # Early stopping nach 5 Iterationen ohne Verbesserung\n",
    "    project='./runs/tensorboard', # logs speichern\n",
    ")\n",
    "\n",
    "# Modell validieren\n",
    "model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e0803ae-b873-4a83-9909-54fa6908f640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /workspace/test2.jpg: 416x416 8 edges, 5 nodes, 17.3ms\n",
      "Speed: 0.7ms preprocess, 17.3ms inference, 0.4ms postprocess per image at shape (1, 3, 416, 416)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Erkennung von Knoten und Kanten\n",
    "###ICI J'ENREGISTRE LE RESULTAT DANS UN FICHIER\n",
    "\n",
    "import cv2\n",
    "# trainiertes model laden \n",
    "model = YOLO('./runs/tensorboard/graph_detection18/weights/best.pt')\n",
    "test = model('/workspace/image.jpg')\n",
    "#test = model('./graph17.jpg')\n",
    "\n",
    "# Zugriffserkennungen für das erste Bild \n",
    "detections = test[0].boxes  # Zugriff auf die Erkennungsboxen\n",
    "\n",
    "# Daten aus Boxen abrufen\n",
    "boxes = detections.xyxy  # Koordinaten der Boxen [x_min, y_min, x_max, y_max]\n",
    "classes = detections.cls  # Vorhergesagte Klassen (0 für Kante, 1 für Knoten in unserem Fall)\n",
    "scores = detections.conf  # Scores\n",
    "\n",
    "\n",
    "# Originalbild laden\n",
    "image = cv2.imread('/workspace/image.jpg')\n",
    "#image = cv2.imread('./graph17.jpg')\n",
    "\n",
    "# Legen Sie für jede Klasse Farben fest\n",
    "colors = {\n",
    "    0: (255, 0, 0),  # Blau für \"edge\"\n",
    "    1: (0, 255, 0)   # grün für \"node\"\n",
    "}\n",
    "\n",
    "# Durchsuchen Sie erkannte Boxen\n",
    "for box, cls, score in zip(boxes, classes, scores):\n",
    "    x_min, y_min, x_max, y_max = map(int, box)  # \n",
    "    if cls == 1 or (cls == 0 and score >= 0.5):\n",
    "        label = f\"{'edge' if cls == 0 else 'node'} {score:.2f}\"\n",
    "        # Zeichnen Sie den Begrenzungsrahmen\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), colors[int(cls)], 2)\n",
    "    \n",
    "        # Fügen Sie das Etikett über der Box hinzu\n",
    "        cv2.putText(image, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colors[int(cls)], 2)\n",
    "    \n",
    "\n",
    "\n",
    "cv2.imwrite('/workspace/image_detections.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dca16d7c-07cb-4430-8a8f-ddd4f953e97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.11/site-packages (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/conda/lib/python3.11/site-packages (from scikit-image) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.11.2 in /opt/conda/lib/python3.11/site-packages (from scikit-image) (1.15.1)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.11/site-packages (from scikit-image) (3.4)\n",
      "Requirement already satisfied: pillow>=10.1 in /opt/conda/lib/python3.11/site-packages (from scikit-image) (11.0.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /opt/conda/lib/python3.11/site-packages (from scikit-image) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.11/site-packages (from scikit-image) (2025.1.10)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.11/site-packages (from scikit-image) (24.1)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.11/site-packages (from scikit-image) (0.4)\n"
     ]
    }
   ],
   "source": [
    "#KNOTEN ENTFERNEN\n",
    "#Erhaltung des Graphen ohne seine Knoten\n",
    "!pip install scikit-image\n",
    "from skimage import io\n",
    "from skimage.draw import rectangle\n",
    "\n",
    "\n",
    "# Originalbild laden\n",
    "image1 = cv2.imread('/workspace/image.jpg')\n",
    "# Hintergrundfarbe zum Ausblenden von Knoten (z. B. weiß)\n",
    "background_color = [255, 255, 255]  # RGB pour blanc\n",
    "for box, cls in zip(boxes, classes):\n",
    "    if cls == 1:  # Klasse 1 entspricht „node“\n",
    "        x_min, y_min, x_max, y_max = map(int, box)\n",
    "        \n",
    "        # Holen Sie sich die Koordinaten des Rechtecks\n",
    "        rr, cc = rectangle(start=(y_min, x_min), extent=(y_max - y_min, x_max - x_min), shape=image1.shape)\n",
    "        \n",
    "        # Füllen Sie den Knotenbereich mit der Hintergrundfarbe\n",
    "        image1[rr, cc] = background_color\n",
    "\n",
    "# Bild ohne Knoten speichern\n",
    "output_path = '/workspace/image_no_nodes.jpg'\n",
    "io.imsave(output_path, image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47a4fe50-d667-4d0a-9c03-176ca4f7c1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /workspace/image_no_nodes.jpg: 416x416 8 edges, 18.5ms\n",
      "Speed: 1.0ms preprocess, 18.5ms inference, 0.5ms postprocess per image at shape (1, 3, 416, 416)\n",
      "5\n",
      "Nœuds du graphe : {0: (102.0, 373.0), 1: (272.0, 68.0), 2: (104.0, 296.0), 3: (362.0, 56.666666666666664), 4: (363.0, 370.0), 5: (67.0, 292.0), 6: (196.0, 296.0), 7: (178.0, 213.0)}\n",
      "Arêtes du graphe : [(0, 1), (2, 3), (4, 5), (6, 3), (7, 3)]\n"
     ]
    }
   ],
   "source": [
    "# ERKENNUNG VON KANTEN + CLUSTERING\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "image2 = cv2.imread('/workspace/image_no_nodes.jpg')\n",
    "\n",
    "def extract_edges_from_yolo(detections, class_edge=0, confidence_threshold=0.5):\n",
    "    \n",
    "    edges = []\n",
    "    # \n",
    "    boxes = detections.xyxy.cpu().numpy()  # Daten von Boxen [x_min, y_min, x_max, y_max]\n",
    "    classes = detections.cls.cpu().numpy()  # Vorhergesagte Klassen (0 für Kante, 1 für Knoten)\n",
    "    scores = detections.conf.cpu().numpy()  #  confiance Scores\n",
    "    for box, cls, conf in zip(boxes, classes, scores):\n",
    "        if cls == class_edge and conf >= confidence_threshold:\n",
    "            #x1, y1, x2, y2 = box[:4]\n",
    "            #edges.append((x1, y1, x2, y2))\n",
    "            edges.append(tuple(map(int, box[:4])))  # in ganze Zahl umwandeln\n",
    "    \n",
    "    return edges\n",
    "\n",
    "def process_edge_roi(img, roi):\n",
    "    \n",
    "    x_min, y_min, x_max, y_max = roi\n",
    "    roi_img = img[y_min:y_max, x_min:x_max]  # Découper la ROI\n",
    "    img_height, img_width = img.shape[:2]\n",
    "    (x1, y1) , (x2, y2) = proceed(roi_img, roi)\n",
    "    return (x1, img_height - y1) , (x2, img_height - y2)\n",
    "\n",
    "def reconstruct_nodes_and_edges(edges_detected, eps=80):\n",
    "    points = []\n",
    "\n",
    "    # Step 1 : Extrahieren Sie Endpunkte für jede Kante\n",
    "    for roi in edges_detected:\n",
    "        roi_points = process_edge_roi(image2, roi)\n",
    "        points.extend(roi_points)\n",
    "    # Step 2 : Clustering der Endepunkten von Kanten \n",
    "    points = np.array(points)\n",
    "    clustering = DBSCAN(eps=eps, min_samples=1).fit(points)\n",
    "    node_labels = clustering.labels_\n",
    "    # Berechnung der Knotenpositionen (Clusterzentren)\n",
    "    nodes = {}\n",
    "    for label in np.unique(node_labels):\n",
    "        cluster_points = points[node_labels == label]\n",
    "        cluster_center = cluster_points.mean(axis=0)\n",
    "        nodes[label] = tuple(cluster_center)\n",
    "    \n",
    " \n",
    "    # Step 3 : Zuordnung von Knoten mit Kanten\n",
    "    edges = []\n",
    "    for roi in edges_detected:\n",
    "        roi_points = process_edge_roi(image2, roi)\n",
    "        #print(roi_points)\n",
    "        if len(roi_points) < 2:\n",
    "            continue  # Ignorieren, wenn nicht genügend Punkte zum Bilden einer Kante vorhanden sind\n",
    "        point1, point2 = roi_points[:2]  # Choisir deux points principaux\n",
    "        node1 = clustering.labels_[np.argmin(np.linalg.norm(points - np.array(point1), axis=1))]\n",
    "        node2 = clustering.labels_[np.argmin(np.linalg.norm(points - np.array(point2), axis=1))]\n",
    "        edges.append((node1, node2))\n",
    "    \n",
    "    return nodes, edges\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test = model('/workspace/image_no_nodes.jpg')\n",
    "detections = test[0].boxes\n",
    "\n",
    "# Schritt 1: Abrufen der erkannten Kanten\n",
    "edges_detected = extract_edges_from_yolo(\n",
    "    detections, \n",
    "    class_edge=0,  # Angenommen, Klasse 0 repräsentiert die Kanten\n",
    "    confidence_threshold=0.4\n",
    ")\n",
    "\n",
    "print(len(edges_detected))\n",
    "# Schritt 2: Knoten und Kanten neu erstellen\n",
    "nodes, edges = reconstruct_nodes_and_edges(edges_detected, eps=35)\n",
    "\n",
    "# Schritt 3: Erstellen Sie das Diagramm\n",
    "graphe = Graph()\n",
    "for node_id, (x, y) in nodes.items():\n",
    "    graphe.add_node(node_id, x, y)\n",
    "\n",
    "for node1, node2 in edges:\n",
    "    graphe.add_edge(node1, node2)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(\"Knoten :\", graphe.nodes)\n",
    "print(\"Kanten :\", graphe.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0197616f-49e4-4d53-bb25-741c1455e3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#GRAPHEN PLOTTEN\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_graph(graphe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2bc341-8f80-4ff1-8084-d5eb215c81fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
